{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7b17c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f0214",
   "metadata": {},
   "source": [
    "## 1. Create different datasets based on the store. (Different in sizes and distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "92bf1673",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train_df = pd.read_csv(\"main_train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2d42a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dict of all the store branches\n",
    "stores = {}\n",
    "for store_id in main_train_df[\"Store\"].unique():\n",
    "    df_store = main_train_df[main_train_df[\"Store\"] == store_id]\n",
    "    stores[f\"store_{store_id}\"] = df_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "887681ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday',\n",
       "       'StoreType', 'Assortment', 'CompetitionDistance',\n",
       "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
       "       'Promo2SinceWeek', 'Promo2SinceYear', 'Year', 'Month', 'Day',\n",
       "       'WeekOfYear', 'Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores[\"store_2\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2a527c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c9738",
   "metadata": {},
   "source": [
    "## 2. Compute metadata info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4c357649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Prevoius simple meta data calculation which did not capture everything fully \\ndef compute_metadata(df):\\n    return {\\n        \"num_rows\": len(df),\\n        \"promo_fraction\": df[\"Promo\"].mean(),\\n        \"promo2_fraction\": df[\"Promo2\"].mean(),\\n        \"schoolholiday_fraction\": df[\"SchoolHoliday\"].mean(),\\n        \"mean_sales\": df[\"Sales\"].mean(),\\n        \"std_sales\": df[\"Sales\"].std()\\n    }\\n'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Prevoius simple meta data calculation which did not capture everything fully \n",
    "def compute_metadata(df):\n",
    "    return {\n",
    "        \"num_rows\": len(df),\n",
    "        \"promo_fraction\": df[\"Promo\"].mean(),\n",
    "        \"promo2_fraction\": df[\"Promo2\"].mean(),\n",
    "        \"schoolholiday_fraction\": df[\"SchoolHoliday\"].mean(),\n",
    "        \"mean_sales\": df[\"Sales\"].mean(),\n",
    "        \"std_sales\": df[\"Sales\"].std()\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "41a2c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metadata(df):\n",
    "    meta = {}\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 1. Basic size features\n",
    "    # ----------------------------------\n",
    "    meta[\"num_rows\"] = len(df)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 2. Sales distribution features\n",
    "    # ----------------------------------\n",
    "    sales = df[\"Sales\"].values\n",
    "\n",
    "    meta[\"mean_sales\"] = np.mean(sales)\n",
    "    meta[\"std_sales\"] = np.std(sales)\n",
    "    meta[\"cv_sales\"] = meta[\"std_sales\"] / (meta[\"mean_sales\"] + 1e-9)\n",
    "    meta[\"skew_sales\"] = skew(sales)\n",
    "    meta[\"kurtosis_sales\"] = kurtosis(sales)\n",
    "    meta[\"entropy_sales\"] = (\n",
    "        pd.Series(sales).value_counts(normalize=True)  # probability distrib\n",
    "        .pipe(lambda p: -(p * np.log2(p + 1e-12))).sum()\n",
    "    )\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 3. Autocorrelation structure\n",
    "    # ----------------------------------\n",
    "    # lag-1, lag-7, lag-30 autocorrelation\n",
    "    try:\n",
    "        ac = acf(sales, nlags=30, fft=True)\n",
    "        meta[\"acf_lag1\"] = ac[1]\n",
    "        meta[\"acf_lag7\"] = ac[7] if len(ac) > 7 else 0\n",
    "        meta[\"acf_lag30\"] = ac[30] if len(ac) > 30 else 0\n",
    "    except:\n",
    "        meta[\"acf_lag1\"] = meta[\"acf_lag7\"] = meta[\"acf_lag30\"] = 0\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 4. Weekly seasonality strength\n",
    "    # ----------------------------------\n",
    "    # variance explained by grouping by weekday\n",
    "    weekday_means = df.groupby(\"DayOfWeek\")[\"Sales\"].mean()\n",
    "    overall_mean = meta[\"mean_sales\"]\n",
    "    ss_between = np.sum((weekday_means - overall_mean) ** 2)\n",
    "    ss_total = np.sum((sales - overall_mean) ** 2)\n",
    "    meta[\"weekday_seasonality_strength\"] = ss_between / (ss_total + 1e-9)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 5. Volatility & noise\n",
    "    # ----------------------------------\n",
    "    diffs = np.diff(sales)\n",
    "    meta[\"volatility\"] = np.std(diffs)\n",
    "    meta[\"jump_fraction\"] = np.mean(np.abs(diffs) > (2 * np.std(diffs)))\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 6. Promotion behaviour features\n",
    "    # ----------------------------------\n",
    "    if \"Promo\" in df:\n",
    "        meta[\"promo_fraction\"] = df[\"Promo\"].mean()\n",
    "        meta[\"promo_sales_corr\"] = np.corrcoef(df[\"Promo\"], sales)[0, 1]\n",
    "    else:\n",
    "        meta[\"promo_fraction\"] = 0\n",
    "        meta[\"promo_sales_corr\"] = 0\n",
    "\n",
    "    if \"Promo2\" in df:\n",
    "        meta[\"promo2_fraction\"] = df[\"Promo2\"].mean()\n",
    "    else:\n",
    "        meta[\"promo2_fraction\"] = 0\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 7. Mutual information from key features\n",
    "    # ----------------------------------\n",
    "    important_features = []\n",
    "    for col in [\"Promo\", \"Promo2\", \"SchoolHoliday\", \"DayOfWeek\", \"Month\", \"WeekOfYear\"]:\n",
    "        if col in df:\n",
    "            important_features.append(col)\n",
    "\n",
    "    if len(important_features) > 0:\n",
    "        mi = mutual_info_regression(df[important_features].fillna(0), sales)\n",
    "        meta[\"mean_mutual_info\"] = np.mean(mi)\n",
    "        meta[\"max_mutual_info\"] = np.max(mi)\n",
    "    else:\n",
    "        meta[\"mean_mutual_info\"] = 0\n",
    "        meta[\"max_mutual_info\"] = 0\n",
    "\n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fca5e5",
   "metadata": {},
   "source": [
    "## 3. Build a dataset of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "47a3ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rows = []\n",
    "for name, df in stores.items():\n",
    "    m = compute_metadata(df)\n",
    "    m[\"label\"] = name      # group name\n",
    "    meta_rows.append(m)\n",
    "\n",
    "meta_df = pd.DataFrame(meta_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8cf01f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_rows</th>\n",
       "      <th>mean_sales</th>\n",
       "      <th>std_sales</th>\n",
       "      <th>cv_sales</th>\n",
       "      <th>skew_sales</th>\n",
       "      <th>kurtosis_sales</th>\n",
       "      <th>entropy_sales</th>\n",
       "      <th>acf_lag1</th>\n",
       "      <th>acf_lag7</th>\n",
       "      <th>acf_lag30</th>\n",
       "      <th>weekday_seasonality_strength</th>\n",
       "      <th>volatility</th>\n",
       "      <th>jump_fraction</th>\n",
       "      <th>promo_fraction</th>\n",
       "      <th>promo_sales_corr</th>\n",
       "      <th>promo2_fraction</th>\n",
       "      <th>mean_mutual_info</th>\n",
       "      <th>max_mutual_info</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743</td>\n",
       "      <td>4606.578735</td>\n",
       "      <td>2481.211280</td>\n",
       "      <td>0.538623</td>\n",
       "      <td>-0.441794</td>\n",
       "      <td>-0.092137</td>\n",
       "      <td>8.295296</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>-0.087699</td>\n",
       "      <td>-0.012871</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>3502.579659</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.382234</td>\n",
       "      <td>0.681371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205151</td>\n",
       "      <td>0.682002</td>\n",
       "      <td>store_44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>741</td>\n",
       "      <td>5672.014845</td>\n",
       "      <td>2994.248067</td>\n",
       "      <td>0.527898</td>\n",
       "      <td>-0.705748</td>\n",
       "      <td>0.045183</td>\n",
       "      <td>8.229686</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.011633</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>4187.874189</td>\n",
       "      <td>0.051351</td>\n",
       "      <td>0.387314</td>\n",
       "      <td>0.534914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154713</td>\n",
       "      <td>0.523504</td>\n",
       "      <td>store_346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>754</td>\n",
       "      <td>5193.153846</td>\n",
       "      <td>2743.642714</td>\n",
       "      <td>0.528319</td>\n",
       "      <td>-0.557344</td>\n",
       "      <td>-0.093521</td>\n",
       "      <td>8.383364</td>\n",
       "      <td>-0.004893</td>\n",
       "      <td>0.022848</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>3885.520866</td>\n",
       "      <td>0.049137</td>\n",
       "      <td>0.393899</td>\n",
       "      <td>0.607224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>0.602030</td>\n",
       "      <td>store_331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761</td>\n",
       "      <td>5701.437582</td>\n",
       "      <td>2996.261045</td>\n",
       "      <td>0.525527</td>\n",
       "      <td>-0.643381</td>\n",
       "      <td>0.109564</td>\n",
       "      <td>8.311891</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.015027</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>4227.378102</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.383706</td>\n",
       "      <td>0.568730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165873</td>\n",
       "      <td>0.520040</td>\n",
       "      <td>store_572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>759</td>\n",
       "      <td>10139.573123</td>\n",
       "      <td>6172.017506</td>\n",
       "      <td>0.608706</td>\n",
       "      <td>-0.139795</td>\n",
       "      <td>-0.469621</td>\n",
       "      <td>8.323018</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>-0.025300</td>\n",
       "      <td>-0.035447</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>8533.371109</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.396574</td>\n",
       "      <td>0.658192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200843</td>\n",
       "      <td>0.762374</td>\n",
       "      <td>store_1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>743</td>\n",
       "      <td>5091.839838</td>\n",
       "      <td>2640.088256</td>\n",
       "      <td>0.518494</td>\n",
       "      <td>-0.779477</td>\n",
       "      <td>0.081218</td>\n",
       "      <td>8.221165</td>\n",
       "      <td>0.047158</td>\n",
       "      <td>0.031503</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>3647.001267</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.379542</td>\n",
       "      <td>0.553360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154943</td>\n",
       "      <td>0.570303</td>\n",
       "      <td>store_588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>739</td>\n",
       "      <td>3597.783491</td>\n",
       "      <td>2023.350920</td>\n",
       "      <td>0.562388</td>\n",
       "      <td>-0.230648</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>8.306722</td>\n",
       "      <td>-0.046617</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>-0.009285</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>2929.142004</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.400541</td>\n",
       "      <td>0.639159</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209718</td>\n",
       "      <td>0.680331</td>\n",
       "      <td>store_486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>770</td>\n",
       "      <td>5498.275325</td>\n",
       "      <td>3151.518510</td>\n",
       "      <td>0.573183</td>\n",
       "      <td>-0.405057</td>\n",
       "      <td>-0.352738</td>\n",
       "      <td>8.210001</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.054237</td>\n",
       "      <td>-0.016821</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>4451.183365</td>\n",
       "      <td>0.036411</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.640810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194054</td>\n",
       "      <td>0.691120</td>\n",
       "      <td>store_917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>751</td>\n",
       "      <td>7627.969374</td>\n",
       "      <td>4055.272810</td>\n",
       "      <td>0.531632</td>\n",
       "      <td>-0.596036</td>\n",
       "      <td>-0.223879</td>\n",
       "      <td>8.349188</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>-0.029155</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>5678.596849</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.379494</td>\n",
       "      <td>0.638681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162047</td>\n",
       "      <td>0.584901</td>\n",
       "      <td>store_683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>618</td>\n",
       "      <td>4412.851133</td>\n",
       "      <td>2308.910594</td>\n",
       "      <td>0.523224</td>\n",
       "      <td>-0.868727</td>\n",
       "      <td>-0.117774</td>\n",
       "      <td>7.941448</td>\n",
       "      <td>-0.041990</td>\n",
       "      <td>-0.066007</td>\n",
       "      <td>0.013927</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>3335.297429</td>\n",
       "      <td>0.040519</td>\n",
       "      <td>0.378641</td>\n",
       "      <td>0.440116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121855</td>\n",
       "      <td>0.572049</td>\n",
       "      <td>store_317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_rows    mean_sales    std_sales  cv_sales  skew_sales  \\\n",
       "0          743   4606.578735  2481.211280  0.538623   -0.441794   \n",
       "1          741   5672.014845  2994.248067  0.527898   -0.705748   \n",
       "2          754   5193.153846  2743.642714  0.528319   -0.557344   \n",
       "3          761   5701.437582  2996.261045  0.525527   -0.643381   \n",
       "4          759  10139.573123  6172.017506  0.608706   -0.139795   \n",
       "...        ...           ...          ...       ...         ...   \n",
       "1110       743   5091.839838  2640.088256  0.518494   -0.779477   \n",
       "1111       739   3597.783491  2023.350920  0.562388   -0.230648   \n",
       "1112       770   5498.275325  3151.518510  0.573183   -0.405057   \n",
       "1113       751   7627.969374  4055.272810  0.531632   -0.596036   \n",
       "1114       618   4412.851133  2308.910594  0.523224   -0.868727   \n",
       "\n",
       "      kurtosis_sales  entropy_sales  acf_lag1  acf_lag7  acf_lag30  \\\n",
       "0          -0.092137       8.295296  0.001982 -0.087699  -0.012871   \n",
       "1           0.045183       8.229686  0.022688  0.011633   0.004933   \n",
       "2          -0.093521       8.383364 -0.004893  0.022848   0.022079   \n",
       "3           0.109564       8.311891  0.003614  0.018470   0.015027   \n",
       "4          -0.469621       8.323018  0.044858 -0.025300  -0.035447   \n",
       "...              ...            ...       ...       ...        ...   \n",
       "1110        0.081218       8.221165  0.047158  0.031503   0.005638   \n",
       "1111        0.013594       8.306722 -0.046617  0.008881  -0.009285   \n",
       "1112       -0.352738       8.210001  0.002826  0.054237  -0.016821   \n",
       "1113       -0.223879       8.349188  0.018526  0.031322  -0.029155   \n",
       "1114       -0.117774       7.941448 -0.041990 -0.066007   0.013927   \n",
       "\n",
       "      weekday_seasonality_strength   volatility  jump_fraction  \\\n",
       "0                         0.006367  3502.579659       0.047170   \n",
       "1                         0.006094  4187.874189       0.051351   \n",
       "2                         0.006443  3885.520866       0.049137   \n",
       "3                         0.005693  4227.378102       0.050000   \n",
       "4                         0.006025  8533.371109       0.036939   \n",
       "...                            ...          ...            ...   \n",
       "1110                      0.006209  3647.001267       0.047170   \n",
       "1111                      0.006318  2929.142004       0.048780   \n",
       "1112                      0.005557  4451.183365       0.036411   \n",
       "1113                      0.006250  5678.596849       0.044000   \n",
       "1114                      0.007525  3335.297429       0.040519   \n",
       "\n",
       "      promo_fraction  promo_sales_corr  promo2_fraction  mean_mutual_info  \\\n",
       "0           0.382234          0.681371              0.0          0.205151   \n",
       "1           0.387314          0.534914              0.0          0.154713   \n",
       "2           0.393899          0.607224              1.0          0.162247   \n",
       "3           0.383706          0.568730              1.0          0.165873   \n",
       "4           0.396574          0.658192              1.0          0.200843   \n",
       "...              ...               ...              ...               ...   \n",
       "1110        0.379542          0.553360              0.0          0.154943   \n",
       "1111        0.400541          0.639159              1.0          0.209718   \n",
       "1112        0.385714          0.640810              0.0          0.194054   \n",
       "1113        0.379494          0.638681              0.0          0.162047   \n",
       "1114        0.378641          0.440116              1.0          0.121855   \n",
       "\n",
       "      max_mutual_info       label  \n",
       "0            0.682002    store_44  \n",
       "1            0.523504   store_346  \n",
       "2            0.602030   store_331  \n",
       "3            0.520040   store_572  \n",
       "4            0.762374  store_1014  \n",
       "...               ...         ...  \n",
       "1110         0.570303   store_588  \n",
       "1111         0.680331   store_486  \n",
       "1112         0.691120   store_917  \n",
       "1113         0.584901   store_683  \n",
       "1114         0.572049   store_317  \n",
       "\n",
       "[1115 rows x 19 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15980e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd30352c",
   "metadata": {},
   "source": [
    "## 4. Train a decision tree to group datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "db26ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of grouping (training the decision tree),  use the one giant model for all the stores and Compute per-store RMSE and group them. \n",
    "# Stores with bad RMSE → “hard” group\n",
    "# Stores with average RMSE → “medium”\n",
    "# Stores with good RMSE → “easy”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "39b66614",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_predictor = TabularPredictor.load(\"AutogluonModels_5min/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "464a9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_rmses = {}\n",
    "\n",
    "for name, df in stores.items():\n",
    "    perf = global_predictor.evaluate(df)\n",
    "    store_rmses[name] = abs(perf[\"root_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0d01460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'store_44': np.float64(427.03360952640526),\n",
       " 'store_346': np.float64(616.0141636042241),\n",
       " 'store_331': np.float64(585.7557191763498),\n",
       " 'store_572': np.float64(496.19500154528595),\n",
       " 'store_1014': np.float64(1172.7844553164641),\n",
       " 'store_630': np.float64(527.3283023811134),\n",
       " 'store_545': np.float64(611.9078797703415),\n",
       " 'store_201': np.float64(461.2834438514096),\n",
       " 'store_1096': np.float64(435.2329064714001),\n",
       " 'store_1111': np.float64(501.838246002304),\n",
       " 'store_918': np.float64(421.03967884933223),\n",
       " 'store_563': np.float64(491.76494007260885),\n",
       " 'store_731': np.float64(584.2620050975702),\n",
       " 'store_406': np.float64(479.52061758359474),\n",
       " 'store_1040': np.float64(633.5579906504358),\n",
       " 'store_232': np.float64(539.8962895168451),\n",
       " 'store_134': np.float64(358.65287362622064),\n",
       " 'store_155': np.float64(495.7663021096319),\n",
       " 'store_221': np.float64(442.1392740704735),\n",
       " 'store_250': np.float64(625.1845422574472),\n",
       " 'store_94': np.float64(532.3873351593719),\n",
       " 'store_653': np.float64(435.4116964003884),\n",
       " 'store_578': np.float64(745.6263852670043),\n",
       " 'store_65': np.float64(420.62767621076904),\n",
       " 'store_872': np.float64(698.0791689271243),\n",
       " 'store_1064': np.float64(584.5034327434446),\n",
       " 'store_915': np.float64(520.6622854562602),\n",
       " 'store_512': np.float64(549.3284800840382),\n",
       " 'store_370': np.float64(530.0990407088868),\n",
       " 'store_714': np.float64(430.48988606307967),\n",
       " 'store_650': np.float64(401.51468084894617),\n",
       " 'store_775': np.float64(597.2407922547683),\n",
       " 'store_378': np.float64(567.2362467836053),\n",
       " 'store_552': np.float64(616.0827507558852),\n",
       " 'store_31': np.float64(391.5087897632704),\n",
       " 'store_254': np.float64(349.70485699957015),\n",
       " 'store_390': np.float64(711.5329738194584),\n",
       " 'store_400': np.float64(544.9611207679328),\n",
       " 'store_519': np.float64(455.9221908646847),\n",
       " 'store_667': np.float64(548.1492977371224),\n",
       " 'store_777': np.float64(352.32201124355583),\n",
       " 'store_1080': np.float64(701.2167570574609),\n",
       " 'store_1087': np.float64(462.6470787614477),\n",
       " 'store_1061': np.float64(547.2748235215894),\n",
       " 'store_315': np.float64(345.0758445600855),\n",
       " 'store_602': np.float64(476.4233537232545),\n",
       " 'store_208': np.float64(345.03195634589105),\n",
       " 'store_1001': np.float64(468.0746626910262),\n",
       " 'store_573': np.float64(342.211276834362),\n",
       " 'store_1054': np.float64(450.524667383643),\n",
       " 'store_1010': np.float64(675.1956246278048),\n",
       " 'store_264': np.float64(1095.2462418374596),\n",
       " 'store_245': np.float64(736.1906833074224),\n",
       " 'store_910': np.float64(423.5817957793824),\n",
       " 'store_843': np.float64(789.0168516031194),\n",
       " 'store_641': np.float64(530.6542412685063),\n",
       " 'store_1075': np.float64(690.2688055627325),\n",
       " 'store_1020': np.float64(602.3221229219452),\n",
       " 'store_806': np.float64(500.1722894243283),\n",
       " 'store_173': np.float64(489.9599339771934),\n",
       " 'store_87': np.float64(482.57647218391935),\n",
       " 'store_764': np.float64(574.0339020739547),\n",
       " 'store_903': np.float64(849.3732090276866),\n",
       " 'store_1094': np.float64(383.36406485312966),\n",
       " 'store_906': np.float64(1045.146273746061),\n",
       " 'store_226': np.float64(564.4145876260762),\n",
       " 'store_536': np.float64(590.1323163303034),\n",
       " 'store_989': np.float64(435.13059154428555),\n",
       " 'store_467': np.float64(1130.7536233317487),\n",
       " 'store_789': np.float64(342.87120023206114),\n",
       " 'store_495': np.float64(404.7874788624836),\n",
       " 'store_351': np.float64(457.79700569381305),\n",
       " 'store_246': np.float64(491.63861450016987),\n",
       " 'store_710': np.float64(440.8395243554922),\n",
       " 'store_902': np.float64(579.1635707324218),\n",
       " 'store_1099': np.float64(832.1980256266772),\n",
       " 'store_27': np.float64(660.6126586881212),\n",
       " 'store_325': np.float64(559.3095740680471),\n",
       " 'store_565': np.float64(445.6940718946621),\n",
       " 'store_566': np.float64(391.2395243561323),\n",
       " 'store_1017': np.float64(576.6843479407235),\n",
       " 'store_279': np.float64(794.7895673714557),\n",
       " 'store_6': np.float64(422.791614429746),\n",
       " 'store_215': np.float64(552.3798873036701),\n",
       " 'store_807': np.float64(562.4297723768733),\n",
       " 'store_898': np.float64(496.3802595963556),\n",
       " 'store_479': np.float64(825.2986722004727),\n",
       " 'store_570': np.float64(605.608776474206),\n",
       " 'store_1082': np.float64(567.6508723385255),\n",
       " 'store_831': np.float64(1205.9754583548665),\n",
       " 'store_46': np.float64(392.87850326351213),\n",
       " 'store_1021': np.float64(768.1605855999985),\n",
       " 'store_86': np.float64(425.2410486293538),\n",
       " 'store_633': np.float64(544.4090693989335),\n",
       " 'store_821': np.float64(529.9168571110831),\n",
       " 'store_1033': np.float64(766.3866299779697),\n",
       " 'store_649': np.float64(309.9966239846725),\n",
       " 'store_745': np.float64(550.8419335402857),\n",
       " 'store_118': np.float64(562.879506740868),\n",
       " 'store_240': np.float64(350.5754473255939),\n",
       " 'store_825': np.float64(401.5141610242224),\n",
       " 'store_782': np.float64(522.5335747251954),\n",
       " 'store_800': np.float64(521.1752274433256),\n",
       " 'store_952': np.float64(564.1812918943416),\n",
       " 'store_105': np.float64(878.2834303308913),\n",
       " 'store_773': np.float64(569.3372643341),\n",
       " 'store_948': np.float64(683.6435712300238),\n",
       " 'store_411': np.float64(582.9640298050043),\n",
       " 'store_654': np.float64(470.8259629385419),\n",
       " 'store_975': np.float64(687.8638149224435),\n",
       " 'store_192': np.float64(841.0588871275554),\n",
       " 'store_656': np.float64(309.16077972747456),\n",
       " 'store_248': np.float64(624.765772386547),\n",
       " 'store_526': np.float64(694.5052249897386),\n",
       " 'store_312': np.float64(352.5283456570998),\n",
       " 'store_590': np.float64(412.6767131690971),\n",
       " 'store_868': np.float64(699.9160461357669),\n",
       " 'store_95': np.float64(565.8723239458247),\n",
       " 'store_995': np.float64(582.5114286011118),\n",
       " 'store_623': np.float64(1081.0956743281179),\n",
       " 'store_685': np.float64(693.8731792481158),\n",
       " 'store_162': np.float64(550.1982363816238),\n",
       " 'store_286': np.float64(511.3776783300887),\n",
       " 'store_972': np.float64(485.62353773539144),\n",
       " 'store_796': np.float64(486.19963185868426),\n",
       " 'store_214': np.float64(757.2650648427971),\n",
       " 'store_636': np.float64(533.6044946602381),\n",
       " 'store_893': np.float64(496.2861639011013),\n",
       " 'store_3': np.float64(531.3921429759848),\n",
       " 'store_568': np.float64(420.6902952465403),\n",
       " 'store_614': np.float64(585.8100300799467),\n",
       " 'store_871': np.float64(543.4911343387906),\n",
       " 'store_1106': np.float64(385.08841986032854),\n",
       " 'store_812': np.float64(407.1125308781856),\n",
       " 'store_36': np.float64(603.8962617380931),\n",
       " 'store_227': np.float64(1070.3158459758686),\n",
       " 'store_375': np.float64(725.0633502553422),\n",
       " 'store_318': np.float64(643.7692343624083),\n",
       " 'store_115': np.float64(515.0544537437006),\n",
       " 'store_302': np.float64(377.99647435358713),\n",
       " 'store_268': np.float64(457.79573825686595),\n",
       " 'store_715': np.float64(543.1869062798942),\n",
       " 'store_54': np.float64(617.819022748996),\n",
       " 'store_876': np.float64(1168.3095123270264),\n",
       " 'store_1050': np.float64(596.2383483124892),\n",
       " 'store_1112': np.float64(902.285517877679),\n",
       " 'store_1098': np.float64(364.05136655253074),\n",
       " 'store_1027': np.float64(1037.8925172442548),\n",
       " 'store_832': np.float64(461.5163241548667),\n",
       " 'store_606': np.float64(428.47694814020866),\n",
       " 'store_187': np.float64(448.3633343027657),\n",
       " 'store_373': np.float64(406.8683863138551),\n",
       " 'store_463': np.float64(467.7133715661404),\n",
       " 'store_866': np.float64(498.5117415686889),\n",
       " 'store_631': np.float64(411.7351453321077),\n",
       " 'store_128': np.float64(523.5106663948644),\n",
       " 'store_548': np.float64(829.448362127198),\n",
       " 'store_1056': np.float64(385.3736682788064),\n",
       " 'store_583': np.float64(328.23229583658747),\n",
       " 'store_493': np.float64(625.0481233906164),\n",
       " 'store_238': np.float64(611.2933049296336),\n",
       " 'store_454': np.float64(379.637684806075),\n",
       " 'store_455': np.float64(745.5433138396631),\n",
       " 'store_362': np.float64(762.7348135514353),\n",
       " 'store_72': np.float64(379.64017448587333),\n",
       " 'store_78': np.float64(325.2253741363653),\n",
       " 'store_786': np.float64(393.8711158137806),\n",
       " 'store_1041': np.float64(414.6431800175773),\n",
       " 'store_576': np.float64(795.6536009565649),\n",
       " 'store_1024': np.float64(410.6246873331558),\n",
       " 'store_234': np.float64(770.7322010396408),\n",
       " 'store_475': np.float64(496.5141165582438),\n",
       " 'store_428': np.float64(504.36680753228586),\n",
       " 'store_616': np.float64(526.6068851011181),\n",
       " 'store_611': np.float64(434.5832931377177),\n",
       " 'store_145': np.float64(743.9029033244815),\n",
       " 'store_969': np.float64(489.48931506231395),\n",
       " 'store_316': np.float64(540.4384039991389),\n",
       " 'store_397': np.float64(477.13650768571273),\n",
       " 'store_449': np.float64(761.6737204920643),\n",
       " 'store_458': np.float64(698.8532767790164),\n",
       " 'store_554': np.float64(484.3985014602639),\n",
       " 'store_284': np.float64(430.07954832017174),\n",
       " 'store_159': np.float64(499.100707577439),\n",
       " 'store_119': np.float64(414.5882739344325),\n",
       " 'store_150': np.float64(603.8333791001126),\n",
       " 'store_48': np.float64(368.47059607755557),\n",
       " 'store_657': np.float64(632.3968354178694),\n",
       " 'store_1030': np.float64(335.84345551547443),\n",
       " 'store_992': np.float64(479.0687871169881),\n",
       " 'store_741': np.float64(551.2938622313768),\n",
       " 'store_68': np.float64(791.8537937740574),\n",
       " 'store_707': np.float64(634.3192939194057),\n",
       " 'store_809': np.float64(768.4126027315809),\n",
       " 'store_446': np.float64(436.81151781194006),\n",
       " 'store_531': np.float64(388.7006520528893),\n",
       " 'store_450': np.float64(736.8878574500711),\n",
       " 'store_930': np.float64(597.9529587587152),\n",
       " 'store_697': np.float64(643.8422808017357),\n",
       " 'store_236': np.float64(420.62791476713244),\n",
       " 'store_661': np.float64(698.367296696016),\n",
       " 'store_769': np.float64(942.1807256089754),\n",
       " 'store_423': np.float64(995.0072776726515),\n",
       " 'store_111': np.float64(466.3644530719191),\n",
       " 'store_768': np.float64(759.5354017843728),\n",
       " 'store_410': np.float64(561.1134601088099),\n",
       " 'store_477': np.float64(502.30109401169767),\n",
       " 'store_448': np.float64(579.2563816768098),\n",
       " 'store_472': np.float64(386.9155598151398),\n",
       " 'store_506': np.float64(498.8242130592647),\n",
       " 'store_494': np.float64(658.8701955074364),\n",
       " 'store_189': np.float64(694.2397025127962),\n",
       " 'store_424': np.float64(535.0760491308602),\n",
       " 'store_900': np.float64(443.6214108066974),\n",
       " 'store_15': np.float64(501.33065327151775),\n",
       " 'store_167': np.float64(700.6905873913109),\n",
       " 'store_523': np.float64(1064.376095689504),\n",
       " 'store_462': np.float64(385.5989381847456),\n",
       " 'store_761': np.float64(599.3011237820674),\n",
       " 'store_644': np.float64(1595.643911693452),\n",
       " 'store_135': np.float64(432.64182497765427),\n",
       " 'store_943': np.float64(490.4696495281613),\n",
       " 'store_465': np.float64(500.41316793586986),\n",
       " 'store_266': np.float64(528.2017318733805),\n",
       " 'store_880': np.float64(507.70437277262687),\n",
       " 'store_20': np.float64(678.305619176732),\n",
       " 'store_1004': np.float64(500.7161592495267),\n",
       " 'store_742': np.float64(484.4966879492544),\n",
       " 'store_129': np.float64(709.8491991926484),\n",
       " 'store_219': np.float64(315.27493715989283),\n",
       " 'store_320': np.float64(1000.6035147242513),\n",
       " 'store_840': np.float64(505.49052777608784),\n",
       " 'store_818': np.float64(499.7499508186309),\n",
       " 'store_646': np.float64(354.9210765866873),\n",
       " 'store_170': np.float64(513.7975511288624),\n",
       " 'store_510': np.float64(642.7013101651359),\n",
       " 'store_1007': np.float64(514.7845515762368),\n",
       " 'store_252': np.float64(708.7948060699503),\n",
       " 'store_335': np.float64(1229.101552628932),\n",
       " 'store_151': np.float64(545.8151575028069),\n",
       " 'store_395': np.float64(332.80505432621356),\n",
       " 'store_779': np.float64(546.963814793262),\n",
       " 'store_130': np.float64(391.56012651151116),\n",
       " 'store_233': np.float64(512.1337945410176),\n",
       " 'store_364': np.float64(710.1305652851934),\n",
       " 'store_147': np.float64(513.1484271077348),\n",
       " 'store_830': np.float64(491.22378571309696),\n",
       " 'store_374': np.float64(440.10527199102177),\n",
       " 'store_288': np.float64(555.827526090172),\n",
       " 'store_348': np.float64(1622.0789816890822),\n",
       " 'store_1107': np.float64(517.9729554619297),\n",
       " 'store_300': np.float64(545.3299841219493),\n",
       " 'store_21': np.float64(501.9458895530028),\n",
       " 'store_415': np.float64(560.8246629652185),\n",
       " 'store_148': np.float64(519.5052332043326),\n",
       " 'store_405': np.float64(362.0487402167249),\n",
       " 'store_229': np.float64(543.996146895597),\n",
       " 'store_212': np.float64(396.31443687023625),\n",
       " 'store_324': np.float64(515.8453559126908),\n",
       " 'store_1037': np.float64(594.5952837794746),\n",
       " 'store_595': np.float64(841.2471078840151),\n",
       " 'store_357': np.float64(1243.2009415445928),\n",
       " 'store_445': np.float64(888.366535040307),\n",
       " 'store_923': np.float64(376.35394326880333),\n",
       " 'store_553': np.float64(702.6104586628236),\n",
       " 'store_24': np.float64(606.8125196839518),\n",
       " 'store_954': np.float64(534.6733014496034),\n",
       " 'store_837': np.float64(507.19288453010336),\n",
       " 'store_664': np.float64(400.30582144524567),\n",
       " 'store_781': np.float64(457.58215539398935),\n",
       " 'store_601': np.float64(392.5848834320782),\n",
       " 'store_502': np.float64(917.3877383617277),\n",
       " 'store_393': np.float64(615.3220659671541),\n",
       " 'store_383': np.float64(906.2883958760991),\n",
       " 'store_33': np.float64(669.5713805667652),\n",
       " 'store_138': np.float64(513.13268848146),\n",
       " 'store_1009': np.float64(473.99282798477657),\n",
       " 'store_59': np.float64(395.35086332769197),\n",
       " 'store_603': np.float64(586.5253963431436),\n",
       " 'store_521': np.float64(463.14252756355324),\n",
       " 'store_80': np.float64(576.8710591869113),\n",
       " 'store_889': np.float64(299.08757792140784),\n",
       " 'store_396': np.float64(743.4302178320909),\n",
       " 'store_921': np.float64(590.1950033026233),\n",
       " 'store_776': np.float64(406.9264466296235),\n",
       " 'store_418': np.float64(456.2213469747145),\n",
       " 'store_747': np.float64(526.2069681512693),\n",
       " 'store_841': np.float64(323.79490308879986),\n",
       " 'store_968': np.float64(466.0086029081321),\n",
       " 'store_962': np.float64(566.8645162449254),\n",
       " 'store_690': np.float64(624.5298253083841),\n",
       " 'store_979': np.float64(456.74448143865),\n",
       " 'store_875': np.float64(429.3406469765204),\n",
       " 'store_492': np.float64(790.7282349432467),\n",
       " 'store_567': np.float64(472.75779582608317),\n",
       " 'store_920': np.float64(506.9671585366403),\n",
       " 'store_185': np.float64(564.678603689549),\n",
       " 'store_1063': np.float64(341.28013706804205),\n",
       " 'store_1058': np.float64(793.6517720745654),\n",
       " 'store_10': np.float64(424.5017008960856),\n",
       " 'store_695': np.float64(483.55956716230634),\n",
       " 'store_459': np.float64(598.0436195274287),\n",
       " 'store_372': np.float64(530.750101762894),\n",
       " 'store_579': np.float64(573.4639066041202),\n",
       " 'store_869': np.float64(447.044283973685),\n",
       " 'store_1067': np.float64(382.0232841262274),\n",
       " 'store_476': np.float64(391.7893695892336),\n",
       " 'store_586': np.float64(1180.1326730707083),\n",
       " 'store_627': np.float64(479.57325796649224),\n",
       " 'store_628': np.float64(575.3219272866215),\n",
       " 'store_1005': np.float64(451.5712020822348),\n",
       " 'store_91': np.float64(752.820118798978),\n",
       " 'store_520': np.float64(348.21478843260826),\n",
       " 'store_191': np.float64(613.7198710514393),\n",
       " 'store_1034': np.float64(463.67393132866863),\n",
       " 'store_332': np.float64(334.9293118772441),\n",
       " 'store_894': np.float64(677.859509376569),\n",
       " 'store_73': np.float64(411.19285611757124),\n",
       " 'store_859': np.float64(534.0710369252498),\n",
       " 'store_647': np.float64(413.57147810738945),\n",
       " 'store_700': np.float64(850.2954250970621),\n",
       " 'store_988': np.float64(511.0184840409259),\n",
       " 'store_263': np.float64(410.8789312152748),\n",
       " 'store_96': np.float64(434.919475769958),\n",
       " 'store_795': np.float64(459.6764424308298),\n",
       " 'store_539': np.float64(627.1406985423812),\n",
       " 'store_933': np.float64(520.1782208605407),\n",
       " 'store_1093': np.float64(690.3596448744012),\n",
       " 'store_967': np.float64(664.5312537957398),\n",
       " 'store_166': np.float64(524.5225739544289),\n",
       " 'store_729': np.float64(660.0116671202068),\n",
       " 'store_594': np.float64(385.5483860648493),\n",
       " 'store_794': np.float64(294.5464299808915),\n",
       " 'store_712': np.float64(526.3560648760098),\n",
       " 'store_427': np.float64(729.0089904541095),\n",
       " 'store_692': np.float64(483.10179313020643),\n",
       " 'store_160': np.float64(382.03349666725006),\n",
       " 'store_1103': np.float64(525.9927295282872),\n",
       " 'store_574': np.float64(550.9876233035299),\n",
       " 'store_813': np.float64(462.81892923664935),\n",
       " 'store_113': np.float64(667.1825235122483),\n",
       " 'store_42': np.float64(650.4940180615689),\n",
       " 'store_820': np.float64(718.0064803210076),\n",
       " 'store_945': np.float64(360.27946791116335),\n",
       " 'store_725': np.float64(404.0985559191335),\n",
       " 'store_878': np.float64(642.1835893670459),\n",
       " 'store_541': np.float64(562.3539687077334),\n",
       " 'store_303': np.float64(1065.6859405578994),\n",
       " 'store_804': np.float64(470.52633379733095),\n",
       " 'store_62': np.float64(619.5538308994317),\n",
       " 'store_267': np.float64(899.3456964953391),\n",
       " 'store_833': np.float64(487.4562591317844),\n",
       " 'store_251': np.float64(1139.834563372608),\n",
       " 'store_838': np.float64(517.0500847635107),\n",
       " 'store_955': np.float64(445.2317420630613),\n",
       " 'store_1042': np.float64(365.2847659232841),\n",
       " 'store_453': np.float64(938.7757937628303),\n",
       " 'store_577': np.float64(425.4938522077329),\n",
       " 'store_873': np.float64(331.93745350844137),\n",
       " 'store_738': np.float64(603.3870126733399),\n",
       " 'store_295': np.float64(526.4902389245248),\n",
       " 'store_547': np.float64(504.6522104572622),\n",
       " 'store_624': np.float64(515.7795707961714),\n",
       " 'store_558': np.float64(331.3373733808878),\n",
       " 'store_389': np.float64(651.3165674676422),\n",
       " 'store_561': np.float64(448.8294705594389),\n",
       " 'store_61': np.float64(543.6488511620832),\n",
       " 'store_347': np.float64(414.7461246071479),\n",
       " 'store_998': np.float64(361.13233839609194),\n",
       " 'store_736': np.float64(522.9483099187208),\n",
       " 'store_228': np.float64(535.2789480384604),\n",
       " 'store_262': np.float64(1564.3571373702607),\n",
       " 'store_349': np.float64(962.6421786125592),\n",
       " 'store_146': np.float64(471.41835588868383),\n",
       " 'store_152': np.float64(492.68380098940696),\n",
       " 'store_662': np.float64(595.798815300441),\n",
       " 'store_550': np.float64(591.225865454776),\n",
       " 'store_259': np.float64(1100.5076871304918),\n",
       " 'store_401': np.float64(556.6391562308377),\n",
       " 'store_311': np.float64(462.66326973195675),\n",
       " 'store_907': np.float64(592.2323920336706),\n",
       " 'store_815': np.float64(833.5758546980117),\n",
       " 'store_514': np.float64(432.8051399174514),\n",
       " 'store_963': np.float64(965.1027569281063),\n",
       " 'store_1025': np.float64(454.7431438358522),\n",
       " 'store_503': np.float64(572.4006833648888),\n",
       " 'store_766': np.float64(445.54322800359125),\n",
       " 'store_755': np.float64(649.4436149174934),\n",
       " 'store_224': np.float64(506.69765401292506),\n",
       " 'store_342': np.float64(745.1585300134874),\n",
       " 'store_826': np.float64(591.5387278402917),\n",
       " 'store_110': np.float64(417.1981037502007),\n",
       " 'store_844': np.float64(392.77594980449896),\n",
       " 'store_600': np.float64(537.8059941348308),\n",
       " 'store_294': np.float64(456.70934815963597),\n",
       " 'store_970': np.float64(339.0284910498775),\n",
       " 'store_434': np.float64(697.2907699751564),\n",
       " 'store_1113': np.float64(522.6130447771021),\n",
       " 'store_634': np.float64(509.3463959961653),\n",
       " 'store_817': np.float64(1327.4925470917221),\n",
       " 'store_799': np.float64(654.2540931468261),\n",
       " 'store_291': np.float64(509.18428963134056),\n",
       " 'store_625': np.float64(495.3106353340908),\n",
       " 'store_35': np.float64(741.9028242489454),\n",
       " 'store_98': np.float64(359.6379605826844),\n",
       " 'store_66': np.float64(424.37292904866666),\n",
       " 'store_19': np.float64(490.45629211849695),\n",
       " 'store_1032': np.float64(727.806065178148),\n",
       " 'store_560': np.float64(1145.4179281441914),\n",
       " 'store_1092': np.float64(655.5495448427978),\n",
       " 'store_161': np.float64(532.5355697357011),\n",
       " 'store_11': np.float64(638.5657315062326),\n",
       " 'store_1078': np.float64(605.9883684708174),\n",
       " 'store_862': np.float64(654.629156353164),\n",
       " 'store_456': np.float64(517.5840993184642),\n",
       " 'store_517': np.float64(917.4642184104652),\n",
       " 'store_956': np.float64(760.4581063025638),\n",
       " 'store_435': np.float64(399.60344113117543),\n",
       " 'store_721': np.float64(566.0215413249249),\n",
       " 'store_886': np.float64(699.727966468981),\n",
       " 'store_788': np.float64(912.1672745845763),\n",
       " 'store_460': np.float64(350.974672315693),\n",
       " 'store_466': np.float64(601.4605141592655),\n",
       " 'store_290': np.float64(498.6357376765218),\n",
       " 'store_927': np.float64(923.7166474027223),\n",
       " 'store_103': np.float64(520.0675418603628),\n",
       " 'store_391': np.float64(659.7659439101818),\n",
       " 'store_824': np.float64(627.6023675548264),\n",
       " 'store_143': np.float64(463.725068971519),\n",
       " 'store_1060': np.float64(445.6471439477153),\n",
       " 'store_490': np.float64(522.8332184833628),\n",
       " 'store_881': np.float64(405.1665356104113),\n",
       " 'store_412': np.float64(699.1421540191976),\n",
       " 'store_179': np.float64(568.2669160534501),\n",
       " 'store_867': np.float64(452.7837828116754),\n",
       " 'store_297': np.float64(411.6745863295732),\n",
       " 'store_883': np.float64(456.9388179741499),\n",
       " 'store_70': np.float64(451.336910170913),\n",
       " 'store_639': np.float64(462.71389543727616),\n",
       " 'store_896': np.float64(481.0871532726851),\n",
       " 'store_713': np.float64(841.9315950410634),\n",
       " 'store_953': np.float64(399.9808028360338),\n",
       " 'store_528': np.float64(596.1976012301076),\n",
       " 'store_361': np.float64(492.42972322762296),\n",
       " 'store_74': np.float64(455.2701867041978),\n",
       " 'store_388': np.float64(520.0713161977368),\n",
       " 'store_1097': np.float64(761.8801827040678),\n",
       " 'store_186': np.float64(345.0572386806094),\n",
       " 'store_363': np.float64(495.74393417251207),\n",
       " 'store_981': np.float64(500.3331460458349),\n",
       " 'store_808': np.float64(556.9989745307495),\n",
       " 'store_727': np.float64(344.1070257245939),\n",
       " 'store_287': np.float64(505.8385797848227),\n",
       " 'store_723': np.float64(545.6348579000835),\n",
       " 'store_932': np.float64(511.07741317199566),\n",
       " 'store_426': np.float64(444.8845996117307),\n",
       " 'store_846': np.float64(649.5142308928745),\n",
       " 'store_283': np.float64(531.3553067190732),\n",
       " 'store_849': np.float64(491.06938291800253),\n",
       " 'store_648': np.float64(420.5313829332493),\n",
       " 'store_605': np.float64(515.1140341587137),\n",
       " 'store_971': np.float64(1063.2155844301556),\n",
       " 'store_655': np.float64(707.7952636964413),\n",
       " 'store_278': np.float64(482.12254052134716),\n",
       " 'store_938': np.float64(526.140657716201),\n",
       " 'store_974': np.float64(800.5106131774384),\n",
       " 'store_123': np.float64(1172.2125935629542),\n",
       " 'store_557': np.float64(504.65483142998454),\n",
       " 'store_853': np.float64(565.3223136248577),\n",
       " 'store_285': np.float64(449.6519266062276),\n",
       " 'store_1090': np.float64(504.0519462931976),\n",
       " 'store_498': np.float64(409.46949885403046),\n",
       " 'store_931': np.float64(512.568035209067),\n",
       " 'store_580': np.float64(838.1987848195965),\n",
       " 'store_854': np.float64(612.5106822312287),\n",
       " 'store_556': np.float64(580.1480760767896),\n",
       " 'store_343': np.float64(593.109720923954),\n",
       " 'store_301': np.float64(403.9818554530353),\n",
       " 'store_983': np.float64(1256.0813397159698),\n",
       " 'store_726': np.float64(769.8544674280304),\n",
       " 'store_790': np.float64(479.80210062757413),\n",
       " 'store_694': np.float64(542.7385883711383),\n",
       " 'store_381': np.float64(558.5397563553005),\n",
       " 'store_899': np.float64(444.60479003493015),\n",
       " 'store_322': np.float64(359.6521352124329),\n",
       " 'store_698': np.float64(917.0423285132463),\n",
       " 'store_1047': np.float64(481.85962610989804),\n",
       " 'store_767': np.float64(460.93798274470197),\n",
       " 'store_591': np.float64(472.3754354665446),\n",
       " 'store_772': np.float64(312.45796078597857),\n",
       " 'store_354': np.float64(549.7232184833952),\n",
       " 'store_193': np.float64(561.2665672323338),\n",
       " 'store_275': np.float64(573.25412467248),\n",
       " 'store_1115': np.float64(527.4595480943758),\n",
       " 'store_1077': np.float64(336.19600263833934),\n",
       " 'store_198': np.float64(362.15075137771083),\n",
       " 'store_125': np.float64(774.5623491220517),\n",
       " 'store_598': np.float64(458.0244343377315),\n",
       " 'store_759': np.float64(517.5914727375948),\n",
       " 'store_977': np.float64(442.3802897721993),\n",
       " 'store_368': np.float64(740.0230757562118),\n",
       " 'store_533': np.float64(760.7551678647964),\n",
       " 'store_1002': np.float64(471.4026230456283),\n",
       " 'store_504': np.float64(561.0215076904797),\n",
       " 'store_339': np.float64(736.3980980346951),\n",
       " 'store_774': np.float64(337.5377021355956),\n",
       " 'store_241': np.float64(475.8966341944348),\n",
       " 'store_329': np.float64(577.2712002589387),\n",
       " 'store_1068': np.float64(417.0910923471342),\n",
       " 'store_663': np.float64(741.4404072146666),\n",
       " 'store_112': np.float64(413.59321617192825),\n",
       " 'store_1019': np.float64(708.8133231308592),\n",
       " 'store_1008': np.float64(398.7866811971196),\n",
       " 'store_682': np.float64(904.8798098081578),\n",
       " 'store_522': np.float64(611.4432632736482),\n",
       " 'store_1084': np.float64(498.1468603770426),\n",
       " 'store_242': np.float64(386.15053012956355),\n",
       " 'store_845': np.float64(434.2850158369676),\n",
       " 'store_144': np.float64(668.1047297965792),\n",
       " 'store_618': np.float64(579.4036495545316),\n",
       " 'store_730': np.float64(672.470236743701),\n",
       " 'store_1048': np.float64(516.7695517817441),\n",
       " 'store_345': np.float64(384.4118972862875),\n",
       " 'store_474': np.float64(502.1609372598045),\n",
       " 'store_277': np.float64(549.4600164556166),\n",
       " 'store_30': np.float64(542.6671739790144),\n",
       " 'store_26': np.float64(485.41528668398286),\n",
       " 'store_164': np.float64(424.38598464415554),\n",
       " 'store_564': np.float64(419.53845455851416),\n",
       " 'store_28': np.float64(953.5719549514648),\n",
       " 'store_217': np.float64(442.8373580560435),\n",
       " 'store_857': np.float64(564.1690742171343),\n",
       " 'store_4': np.float64(680.2252115461022),\n",
       " 'store_468': np.float64(741.6868468736434),\n",
       " 'store_43': np.float64(591.8104536656116),\n",
       " 'store_665': np.float64(912.4966616867312),\n",
       " 'store_966': np.float64(396.3515906584024),\n",
       " 'store_659': np.float64(494.53622947887357),\n",
       " 'store_505': np.float64(414.7625008213225),\n",
       " 'store_270': np.float64(508.72800840866785),\n",
       " 'store_787': np.float64(652.2944860504753),\n",
       " 'store_530': np.float64(698.192152884583),\n",
       " 'store_79': np.float64(417.26984729013896),\n",
       " 'store_666': np.float64(558.4181657208267),\n",
       " 'store_355': np.float64(632.1060210124759),\n",
       " 'store_901': np.float64(515.8772492739367),\n",
       " 'store_309': np.float64(520.9349305263046),\n",
       " 'store_409': np.float64(473.7037534751613),\n",
       " 'store_137': np.float64(652.8510678135234),\n",
       " 'store_913': np.float64(772.3433421376324),\n",
       " 'store_258': np.float64(438.1187090071985),\n",
       " 'store_392': np.float64(464.63132329034784),\n",
       " 'store_106': np.float64(1027.036886853067),\n",
       " 'store_680': np.float64(487.1390477198395),\n",
       " 'store_1104': np.float64(431.3010791144864),\n",
       " 'store_416': np.float64(705.5990506486771),\n",
       " 'store_936': np.float64(577.7427104842792),\n",
       " 'store_394': np.float64(637.3546861720398),\n",
       " 'store_615': np.float64(716.5171773758514),\n",
       " 'store_850': np.float64(524.2862313332585),\n",
       " 'store_165': np.float64(335.9411799729934),\n",
       " 'store_131': np.float64(536.2709806187555),\n",
       " 'store_338': np.float64(625.2507654251046),\n",
       " 'store_928': np.float64(567.821773123053),\n",
       " 'store_402': np.float64(509.45665034121805),\n",
       " 'store_321': np.float64(492.30712869761254),\n",
       " 'store_643': np.float64(616.0011722909715),\n",
       " 'store_516': np.float64(488.34053657433174),\n",
       " 'store_122': np.float64(696.7031245643886),\n",
       " 'store_276': np.float64(355.0821746501813),\n",
       " 'store_1065': np.float64(379.9750444090815),\n",
       " 'store_693': np.float64(561.3046099511674),\n",
       " 'store_367': np.float64(372.1134880085449),\n",
       " 'store_327': np.float64(619.5676488794945),\n",
       " 'store_1070': np.float64(492.97950024287366),\n",
       " 'store_706': np.float64(405.66446968878626),\n",
       " 'store_197': np.float64(505.38022918853585),\n",
       " 'store_658': np.float64(489.44380476368235),\n",
       " 'store_819': np.float64(419.32754580597856),\n",
       " 'store_473': np.float64(369.58116597479034),\n",
       " 'store_76': np.float64(600.4710295665643),\n",
       " 'store_939': np.float64(498.36078641128546),\n",
       " 'store_440': np.float64(428.62640967510805),\n",
       " 'store_986': np.float64(852.994481483878),\n",
       " 'store_1026': np.float64(757.0188268479419),\n",
       " 'store_839': np.float64(413.598523848915),\n",
       " 'store_17': np.float64(434.1703859869613),\n",
       " 'store_491': np.float64(499.81951624054955),\n",
       " 'store_52': np.float64(683.7194616672514),\n",
       " 'store_230': np.float64(533.460154760894),\n",
       " 'store_444': np.float64(1083.8105578515626),\n",
       " 'store_158': np.float64(656.8574061881797),\n",
       " 'store_816': np.float64(571.3142910062573),\n",
       " 'store_792': np.float64(532.026781596997),\n",
       " 'store_589': np.float64(901.2156901045827),\n",
       " 'store_257': np.float64(447.0155126537708),\n",
       " 'store_471': np.float64(501.4663084948009),\n",
       " 'store_1055': np.float64(462.60579341867145),\n",
       " 'store_737': np.float64(493.11242480646115),\n",
       " 'store_585': np.float64(616.914013227157),\n",
       " 'store_330': np.float64(471.39220393942566),\n",
       " 'store_313': np.float64(491.83325967697834),\n",
       " 'store_1051': np.float64(750.2726053342409),\n",
       " 'store_534': np.float64(708.2095064269882),\n",
       " 'store_1013': np.float64(330.26219083887554),\n",
       " 'store_620': np.float64(496.284447307191),\n",
       " 'store_353': np.float64(579.9339556148559),\n",
       " 'store_549': np.float64(379.42143518344153),\n",
       " 'store_660': np.float64(362.0554579278952),\n",
       " 'store_69': np.float64(678.6573385953773),\n",
       " 'store_1012': np.float64(455.069995047706),\n",
       " 'store_987': np.float64(570.9837723337527),\n",
       " 'store_587': np.float64(892.062447609552),\n",
       " 'store_863': np.float64(619.2459234618213),\n",
       " 'store_681': np.float64(630.9692954425389),\n",
       " 'store_835': np.float64(648.7826802734257),\n",
       " 'store_386': np.float64(805.2436699094643),\n",
       " 'store_1022': np.float64(513.1409273787842),\n",
       " 'store_1095': np.float64(401.4003637414958),\n",
       " 'store_1031': np.float64(429.1055147201623),\n",
       " 'store_673': np.float64(503.3359227705121),\n",
       " 'store_1066': np.float64(787.0072688029965),\n",
       " 'store_916': np.float64(412.00009460677086),\n",
       " 'store_97': np.float64(467.4689682837496),\n",
       " 'store_803': np.float64(852.2484132957677),\n",
       " 'store_991': np.float64(554.5411642978231),\n",
       " 'store_1102': np.float64(469.2273123152236),\n",
       " 'store_175': np.float64(513.2871178699914),\n",
       " 'store_336': np.float64(714.877484433189),\n",
       " 'store_897': np.float64(1444.1924224908234),\n",
       " 'store_686': np.float64(451.76383000610764),\n",
       " 'store_32': np.float64(367.90049058918714),\n",
       " 'store_478': np.float64(509.4811579011729),\n",
       " 'store_380': np.float64(1094.9305810012224),\n",
       " 'store_177': np.float64(349.4577570709484),\n",
       " 'store_687': np.float64(560.9270156118785),\n",
       " 'store_371': np.float64(511.6218827283029),\n",
       " 'store_1052': np.float64(497.55246542850614),\n",
       " 'store_398': np.float64(430.8209769524036),\n",
       " 'store_1036': np.float64(412.55422500142583),\n",
       " 'store_404': np.float64(604.9032430145215),\n",
       " 'store_559': np.float64(487.14969831183606),\n",
       " 'store_323': np.float64(480.9473951179887),\n",
       " 'store_596': np.float64(406.3795612271585),\n",
       " 'store_422': np.float64(393.5349559489907),\n",
       " 'store_142': np.float64(441.79742370854865),\n",
       " 'store_829': np.float64(457.96278361062974),\n",
       " 'store_282': np.float64(309.59858381090646),\n",
       " 'store_344': np.float64(670.3819577520013),\n",
       " 'store_749': np.float64(509.55801198660987),\n",
       " 'store_413': np.float64(556.507450658914),\n",
       " 'store_359': np.float64(488.18072016723755),\n",
       " 'store_419': np.float64(413.0898591974736),\n",
       " 'store_793': np.float64(474.0657839601426),\n",
       " 'store_356': np.float64(459.72012821918145),\n",
       " 'store_607': np.float64(394.28336639470007),\n",
       " 'store_652': np.float64(474.564541237966),\n",
       " 'store_2': np.float64(441.84531715835266),\n",
       " 'store_814': np.float64(611.6947139703454),\n",
       " 'store_905': np.float64(885.3989975450281),\n",
       " 'store_499': np.float64(481.3043829016633),\n",
       " 'store_719': np.float64(513.0131992946357),\n",
       " 'store_49': np.float64(542.2372602914803),\n",
       " 'store_169': np.float64(965.7336138331148),\n",
       " 'store_480': np.float64(350.30602163942075),\n",
       " 'store_973': np.float64(609.3554057572477),\n",
       " 'store_1039': np.float64(1182.6759604358824),\n",
       " 'store_1100': np.float64(640.5679821788402),\n",
       " 'store_414': np.float64(490.66842116583086),\n",
       " 'store_1083': np.float64(486.89544561975856),\n",
       " 'store_762': np.float64(652.5270367331829),\n",
       " 'store_319': np.float64(552.9625127833615),\n",
       " 'store_571': np.float64(560.9834556183824),\n",
       " 'store_1079': np.float64(635.6374569765635),\n",
       " 'store_834': np.float64(402.8437914851194),\n",
       " 'store_527': np.float64(716.1756597050293),\n",
       " 'store_488': np.float64(338.3022889942112),\n",
       " 'store_350': np.float64(503.9311570223485),\n",
       " 'store_376': np.float64(673.6209750683606),\n",
       " 'store_828': np.float64(395.13108724961234),\n",
       " 'store_205': np.float64(469.1287223815007),\n",
       " 'store_535': np.float64(709.7406615027506),\n",
       " 'store_1011': np.float64(762.1670510952542),\n",
       " 'store_272': np.float64(407.6579507436576),\n",
       " 'store_196': np.float64(372.76522388648607),\n",
       " 'store_538': np.float64(326.07223132411605),\n",
       " 'store_805': np.float64(526.744965027005),\n",
       " 'store_885': np.float64(614.6250767659413),\n",
       " 'store_508': np.float64(544.8341795803476),\n",
       " 'store_136': np.float64(652.8996471340407),\n",
       " 'store_613': np.float64(420.1305592877859),\n",
       " 'store_256': np.float64(938.3561402423919),\n",
       " 'store_629': np.float64(679.8225901210877),\n",
       " 'store_669': np.float64(352.80719916648786),\n",
       " 'store_887': np.float64(672.8337447553281),\n",
       " 'store_5': np.float64(395.77163978678254),\n",
       " 'store_436': np.float64(410.4036168565147),\n",
       " 'store_253': np.float64(543.7266079594688),\n",
       " 'store_438': np.float64(463.2316870043753),\n",
       " 'store_429': np.float64(445.2583379672404),\n",
       " 'store_269': np.float64(726.4918306451439),\n",
       " 'store_1088': np.float64(447.33888630574967),\n",
       " 'store_182': np.float64(452.62863693212915),\n",
       " 'store_957': np.float64(499.0557269838399),\n",
       " 'store_23': np.float64(414.052582560822),\n",
       " 'store_202': np.float64(453.7840488465774),\n",
       " 'store_1091': np.float64(564.6463448676202),\n",
       " 'store_911': np.float64(598.83093397312),\n",
       " 'store_507': np.float64(568.4135749569531),\n",
       " 'store_237': np.float64(338.71080812841194),\n",
       " 'store_1028': np.float64(394.7816269319575),\n",
       " 'store_752': np.float64(520.517919689705),\n",
       " 'store_157': np.float64(683.1937750210801),\n",
       " 'store_365': np.float64(443.50763431532863),\n",
       " 'store_739': np.float64(658.2099597200723),\n",
       " 'store_645': np.float64(882.7532619326051),\n",
       " 'store_457': np.float64(454.5892876050258),\n",
       " 'store_260': np.float64(430.8192756834449),\n",
       " 'store_632': np.float64(454.41918301654005),\n",
       " 'store_306': np.float64(348.65930759879325),\n",
       " 'store_430': np.float64(675.02878591408),\n",
       " 'store_14': np.float64(376.41737628163685),\n",
       " 'store_569': np.float64(368.5283400895917),\n",
       " 'store_937': np.float64(723.6654057777868),\n",
       " 'store_77': np.float64(516.6222221630223),\n",
       " 'store_515': np.float64(642.0161762488943),\n",
       " 'store_39': np.float64(600.3235275850677),\n",
       " 'store_225': np.float64(430.14084343581885),\n",
       " 'store_1023': np.float64(539.8927330950494),\n",
       " 'store_593': np.float64(746.9977737774568),\n",
       " 'store_951': np.float64(574.5191849528994),\n",
       " 'store_754': np.float64(617.1860086717162),\n",
       " 'store_743': np.float64(333.0210357542741),\n",
       " 'store_982': np.float64(609.8970633164746),\n",
       " 'store_976': np.float64(434.71061324792026),\n",
       " 'store_47': np.float64(534.3471979958001),\n",
       " 'store_888': np.float64(561.7813342706438),\n",
       " 'store_377': np.float64(763.3211003091745),\n",
       " 'store_56': np.float64(655.0546540372445),\n",
       " 'store_64': np.float64(732.5857613202108),\n",
       " 'store_447': np.float64(385.8326746641309),\n",
       " 'store_50': np.float64(355.63668887826054),\n",
       " 'store_1': np.float64(416.916965557061),\n",
       " 'store_81': np.float64(529.8754391033718),\n",
       " 'store_57': np.float64(1416.4935073420504),\n",
       " 'store_63': np.float64(561.2966117082684),\n",
       " 'store_708': np.float64(922.183071959516),\n",
       " 'store_914': np.float64(590.2792877874272),\n",
       " 'store_333': np.float64(582.5235311307468),\n",
       " 'store_38': np.float64(511.3351550549293),\n",
       " 'store_452': np.float64(554.1700665170188),\n",
       " 'store_487': np.float64(499.45793368597054),\n",
       " 'store_296': np.float64(515.2451388690289),\n",
       " 'store_925': np.float64(877.0732846192087),\n",
       " 'store_827': np.float64(1239.3837449735577),\n",
       " 'store_750': np.float64(414.00486468063883),\n",
       " 'store_441': np.float64(551.5020491452552),\n",
       " 'store_220': np.float64(558.7490002206058),\n",
       " 'store_677': np.float64(629.3864680106342),\n",
       " 'store_8': np.float64(483.5772576375999),\n",
       " 'store_513': np.float64(1039.9527412681268),\n",
       " 'store_500': np.float64(472.68661077755445),\n",
       " 'store_984': np.float64(541.9745091496869),\n",
       " 'store_870': np.float64(704.9134835202631),\n",
       " 'store_464': np.float64(727.0456883576346),\n",
       " 'store_183': np.float64(791.6989900793542),\n",
       " 'store_22': np.float64(369.11446997849777),\n",
       " 'store_1035': np.float64(386.8953132418994),\n",
       " 'store_40': np.float64(539.840603174185),\n",
       " 'store_1057': np.float64(506.24962898317796),\n",
       " 'store_810': np.float64(381.9888725290172),\n",
       " 'store_582': np.float64(585.7251469668007),\n",
       " 'store_360': np.float64(410.5395822866674),\n",
       " 'store_261': np.float64(1011.7309641921611),\n",
       " 'store_249': np.float64(396.7295244287095),\n",
       " 'store_704': np.float64(622.5820026910837),\n",
       " 'store_379': np.float64(321.92726094899746),\n",
       " 'store_848': np.float64(962.9058011554839),\n",
       " 'store_621': np.float64(542.5288607112637),\n",
       " 'store_25': np.float64(1263.0276331074172),\n",
       " 'store_403': np.float64(528.7303274391712),\n",
       " 'store_83': np.float64(349.1654337549283),\n",
       " 'store_604': np.float64(627.7632964225025),\n",
       " 'store_1114': np.float64(1373.89232925401),\n",
       " 'store_420': np.float64(383.65202243075936),\n",
       " 'store_959': np.float64(496.3199787169566),\n",
       " 'store_716': np.float64(434.3724908792554),\n",
       " 'store_935': np.float64(421.6815421633145),\n",
       " 'store_1086': np.float64(710.9146136111535),\n",
       " 'store_942': np.float64(571.7846443647086),\n",
       " 'store_638': np.float64(410.32188747249734),\n",
       " 'store_314': np.float64(351.86438248402015),\n",
       " 'store_53': np.float64(404.3396284751438),\n",
       " 'store_740': np.float64(509.2322088161872),\n",
       " 'store_271': np.float64(669.4949513391251),\n",
       " 'store_529': np.float64(497.9209841659192),\n",
       " 'store_551': np.float64(592.4894920117426),\n",
       " 'store_16': np.float64(506.1745665877095),\n",
       " 'store_341': np.float64(443.5742556133299),\n",
       " 'store_172': np.float64(738.8457293296022),\n",
       " 'store_107': np.float64(455.3680313239968),\n",
       " 'store_443': np.float64(409.3084747669809),\n",
       " 'store_100': np.float64(907.2261106346832),\n",
       " 'store_919': np.float64(434.65867810476647),\n",
       " 'store_126': np.float64(1673.416868333325),\n",
       " 'store_949': np.float64(439.9347918655836),\n",
       " 'store_265': np.float64(442.2117303847951),\n",
       " 'store_757': np.float64(505.8186355138767),\n",
       " 'store_760': np.float64(613.28350674429),\n",
       " 'store_382': np.float64(571.0171058989299),\n",
       " 'store_1108': np.float64(464.2382502637108),\n",
       " 'store_753': np.float64(611.4694493421756),\n",
       " 'store_433': np.float64(477.9426748053852),\n",
       " 'store_626': np.float64(655.1217703638615),\n",
       " 'store_127': np.float64(404.04304079637336),\n",
       " 'store_34': np.float64(471.85978644171337),\n",
       " 'store_1105': np.float64(391.0675272962305),\n",
       " 'store_811': np.float64(370.2439608242941),\n",
       " 'store_178': np.float64(616.1349088938082),\n",
       " 'store_709': np.float64(638.7158209607314),\n",
       " 'store_484': np.float64(620.0975676255223),\n",
       " 'store_728': np.float64(394.266599218516),\n",
       " 'store_222': np.float64(374.5917587077587),\n",
       " 'store_154': np.float64(565.6892958574191),\n",
       " 'store_340': np.float64(496.28723101056727),\n",
       " 'store_688': np.float64(297.31103568497167),\n",
       " 'store_944': np.float64(532.0015400859755),\n",
       " 'store_188': np.float64(428.17203965727816),\n",
       " 'store_195': np.float64(816.329207411628),\n",
       " 'store_304': np.float64(503.1219719534132),\n",
       " 'store_71': np.float64(606.939717682265),\n",
       " 'store_599': np.float64(672.0697650786504),\n",
       " 'store_640': np.float64(627.515661280985),\n",
       " 'store_60': np.float64(675.3272336227703),\n",
       " 'store_678': np.float64(827.5209063300931),\n",
       " 'store_609': np.float64(369.9540227230387),\n",
       " 'store_732': np.float64(706.6989381664306),\n",
       " 'store_1029': np.float64(412.94797411724164),\n",
       " 'store_720': np.float64(488.0044393896991),\n",
       " 'store_9': np.float64(502.23718331585735),\n",
       " 'store_298': np.float64(642.2873033851054),\n",
       " 'store_92': np.float64(518.6046049176565),\n",
       " 'store_765': np.float64(645.1468227039053),\n",
       " 'store_121': np.float64(387.5705745026311),\n",
       " 'store_724': np.float64(550.8036585884554),\n",
       " 'store_82': np.float64(611.8271015806731),\n",
       " 'store_132': np.float64(479.06529721353115),\n",
       " 'store_204': np.float64(341.9686286432506),\n",
       " 'store_328': np.float64(345.01346300499716),\n",
       " 'store_99': np.float64(467.1581902473457),\n",
       " 'store_1006': np.float64(461.48192518082055),\n",
       " 'store_101': np.float64(516.4371736870028),\n",
       " 'store_485': np.float64(373.06778659859776),\n",
       " 'store_90': np.float64(673.6925728659514),\n",
       " 'store_947': np.float64(738.9228561572501),\n",
       " 'store_852': np.float64(439.23699427034023),\n",
       " 'store_139': np.float64(513.9549354464285),\n",
       " 'store_293': np.float64(398.6064369915665),\n",
       " 'store_470': np.float64(1261.624630126766),\n",
       " 'store_102': np.float64(723.2141777513048),\n",
       " 'store_999': np.float64(691.6978079475824),\n",
       " 'store_171': np.float64(476.75702209690996),\n",
       " 'store_1076': np.float64(385.2898563569072),\n",
       " 'store_190': np.float64(436.17512432897547),\n",
       " 'store_180': np.float64(500.7399303322996),\n",
       " 'store_308': np.float64(949.2716365249044),\n",
       " 'store_544': np.float64(1047.966103405229),\n",
       " 'store_437': np.float64(748.0093978786809),\n",
       " 'store_451': np.float64(478.97504374400336),\n",
       " 'store_924': np.float64(374.1534359728404),\n",
       " 'store_993': np.float64(554.481037710536),\n",
       " 'store_280': np.float64(509.06537093032074),\n",
       " 'store_960': np.float64(525.5332455318143),\n",
       " 'store_597': np.float64(443.872675456221),\n",
       " 'store_1018': np.float64(835.8144869594955),\n",
       " 'store_524': np.float64(649.8462819882634),\n",
       " 'store_997': np.float64(448.8077996972875),\n",
       " 'store_281': np.float64(402.2862596247299),\n",
       " 'store_1072': np.float64(563.5910162731956),\n",
       " 'store_679': np.float64(608.7690731047742),\n",
       " 'store_1074': np.float64(429.07335306061435),\n",
       " 'store_608': np.float64(795.9126340831255),\n",
       " 'store_29': np.float64(482.56366528320666),\n",
       " 'store_965': np.float64(709.7407939772554),\n",
       " 'store_994': np.float64(435.0795234179462),\n",
       " 'store_946': np.float64(321.0655555308818),\n",
       " 'store_980': np.float64(546.4144363530611),\n",
       " 'store_153': np.float64(534.070881641692),\n",
       " 'store_860': np.float64(453.2922386166252),\n",
       " 'store_674': np.float64(1107.1268352908166),\n",
       " 'store_637': np.float64(615.2072700383886),\n",
       " 'store_274': np.float64(535.9140859558679),\n",
       " 'store_990': np.float64(431.8804631450535),\n",
       " 'store_791': np.float64(587.0627226428375),\n",
       " 'store_540': np.float64(497.4634365045004),\n",
       " 'store_780': np.float64(469.9251394140994),\n",
       " 'store_684': np.float64(580.8427999940515),\n",
       " 'store_84': np.float64(846.5974332775254),\n",
       " 'store_771': np.float64(494.41390691005256),\n",
       " 'store_985': np.float64(1267.1465176612026),\n",
       " 'store_1053': np.float64(533.5966904832684),\n",
       " 'store_431': np.float64(667.6290739650057),\n",
       " 'store_210': np.float64(333.0642283459063),\n",
       " 'store_384': np.float64(666.8173150127458),\n",
       " 'store_882': np.float64(868.498715210134),\n",
       " 'store_425': np.float64(335.85742643916564),\n",
       " 'store_244': np.float64(449.4649119617878),\n",
       " 'store_51': np.float64(562.8772992044787),\n",
       " 'store_255': np.float64(490.48391731692703),\n",
       " 'store_584': np.float64(408.6866515246092),\n",
       " 'store_89': np.float64(409.87120589692137),\n",
       " 'store_861': np.float64(431.4520183344066),\n",
       " 'store_612': np.float64(590.728108700823),\n",
       " 'store_326': np.float64(416.5007625327594),\n",
       " 'store_408': np.float64(373.11527228801816),\n",
       " 'store_289': np.float64(458.1611454290474),\n",
       " 'store_482': np.float64(625.2319579489557),\n",
       " 'store_141': np.float64(411.9313822364255),\n",
       " 'store_864': np.float64(385.83621702668034),\n",
       " 'store_213': np.float64(660.7481191657055),\n",
       " 'store_199': np.float64(565.273508181481),\n",
       " 'store_1089': np.float64(734.5942487531581),\n",
       " 'store_1085': np.float64(493.0877584806561),\n",
       " 'store_746': np.float64(506.02318518224445),\n",
       " 'store_469': np.float64(753.396096367531),\n",
       " 'store_865': np.float64(653.8473045192796),\n",
       " 'store_701': np.float64(428.4204185228804),\n",
       " 'store_909': np.float64(1833.0825196414646),\n",
       " 'store_299': np.float64(808.3836429502868),\n",
       " 'store_41': np.float64(504.3813561768369),\n",
       " 'store_778': np.float64(449.8551505577405),\n",
       " 'store_85': np.float64(764.0438018365952),\n",
       " 'store_622': np.float64(323.74998355322947),\n",
       " 'store_13': np.float64(528.1701505014005),\n",
       " 'store_239': np.float64(535.1999636073815),\n",
       " 'store_1110': np.float64(354.0076968611333),\n",
       " 'store_399': np.float64(481.907371279165),\n",
       " 'store_206': np.float64(561.556651232854),\n",
       " 'store_763': np.float64(443.63752964001003),\n",
       " 'store_801': np.float64(425.33955198727136),\n",
       " 'store_7': np.float64(637.1003148463465),\n",
       " 'store_273': np.float64(500.1839119227417),\n",
       " 'store_1003': np.float64(796.7720489762156),\n",
       " 'store_305': np.float64(473.1034185916145),\n",
       " 'store_856': np.float64(477.4297869387261),\n",
       " 'store_163': np.float64(728.1156500726058),\n",
       " 'store_247': np.float64(565.6235872581748),\n",
       " 'store_352': np.float64(519.0804104796699),\n",
       " 'store_751': np.float64(520.9436002050568),\n",
       " 'store_671': np.float64(450.74343172928775),\n",
       " 'store_67': np.float64(518.9946192149858),\n",
       " 'store_950': np.float64(411.2857693290628),\n",
       " 'store_417': np.float64(561.1314010381121),\n",
       " 'store_874': np.float64(385.21610921743206),\n",
       " 'store_758': np.float64(390.6126681421691),\n",
       " 'store_703': np.float64(310.95636048216613),\n",
       " 'store_961': np.float64(454.42936854406935),\n",
       " 'store_501': np.float64(491.59919437762875),\n",
       " 'store_334': np.float64(416.4161111813883),\n",
       " 'store_37': np.float64(539.6763787008392),\n",
       " 'store_1049': np.float64(331.07517926562184),\n",
       " 'store_784': np.float64(662.1669110657969),\n",
       " 'store_525': np.float64(626.0088368505207),\n",
       " 'store_543': np.float64(396.61490881936606),\n",
       " 'store_497': np.float64(642.5731786131544),\n",
       " 'store_858': np.float64(372.30103091382273),\n",
       " 'store_798': np.float64(498.4485850050117),\n",
       " 'store_1062': np.float64(448.6900316644579),\n",
       " 'store_705': np.float64(551.575974667005),\n",
       " 'store_642': np.float64(313.9874969661344),\n",
       " 'store_610': np.float64(338.2488939056359),\n",
       " 'store_696': np.float64(607.3173795094623),\n",
       " 'store_904': np.float64(504.2599037707654),\n",
       " 'store_718': np.float64(483.2252021512836),\n",
       " 'store_855': np.float64(438.5829751106615),\n",
       " 'store_75': np.float64(444.87574262085576),\n",
       " 'store_168': np.float64(548.5750520024803),\n",
       " 'store_518': np.float64(473.06286510711925),\n",
       " 'store_116': np.float64(467.5849728756964),\n",
       " 'store_822': np.float64(637.8621271975046),\n",
       " 'store_509': np.float64(448.7907027120937),\n",
       " 'store_575': np.float64(522.2148580179276),\n",
       " 'store_194': np.float64(361.3873931729346),\n",
       " 'store_532': np.float64(1056.4804880946695),\n",
       " 'store_149': np.float64(486.2039466468365),\n",
       " 'store_756': np.float64(1303.1547133349504),\n",
       " 'store_461': np.float64(589.3521164050962),\n",
       " 'store_689': np.float64(567.3674179510432),\n",
       " 'store_941': np.float64(408.45130670533416),\n",
       " 'store_114': np.float64(415.9342493937182),\n",
       " 'store_1038': np.float64(433.6952156231459),\n",
       " 'store_216': np.float64(590.2806895118523),\n",
       " 'store_744': np.float64(601.5624218407501),\n",
       " 'store_851': np.float64(494.2022154125412),\n",
       " 'store_231': np.float64(412.0242151054327),\n",
       " 'store_929': np.float64(386.8098615549493),\n",
       " 'store_1101': np.float64(544.8470292906333),\n",
       " 'store_200': np.float64(578.1106294566448),\n",
       " 'store_176': np.float64(404.49454530010627),\n",
       " 'store_823': np.float64(426.1199336617515),\n",
       " ...}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349eab69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "347a84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_group_by_rmse(rmse):\n",
    "    if rmse > 800:\n",
    "        return \"hard\"\n",
    "    elif rmse > 650:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"easy\"\n",
    "\n",
    "meta_df[\"group\"] = meta_df[\"label\"].apply(lambda s: assign_group_by_rmse(store_rmses[s]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ae649dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "easy      860\n",
       "medium    151\n",
       "hard      104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5de1e16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_leaf=2, n_estimators=300, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=2, n_estimators=300, random_state=42)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X = meta_df.drop(columns=[\"group\" , \"label\"])\n",
    "y = meta_df[\"group\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1d4e2b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8243727598566308\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537e0ce",
   "metadata": {},
   "source": [
    "## 5. Train an AutoGluon model for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8684a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"Models_group/easy/\"\n",
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.4.0: Fri Mar 15 00:19:22 PDT 2024; root:xnu-10063.101.17~1/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.33 GB / 8.00 GB (16.6%)\n",
      "Disk Space Avail:   53.29 GB / 228.27 GB (23.3%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for group: easy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"/Users/sepideghorbanian/Documents/Semester_5/Research_Project/Models_group/easy\"\n",
      "Train Data Rows:    626941\n",
      "Train Data Columns: 18\n",
      "Label Column:       Sales\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (26807, 0, 5153.42366, 3159.48365)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1509.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 175.78 MB (11.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 11.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  5 | ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
      "\t\t('int', [])    : 10 | ['Store', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', ...]\n",
      "\t\t('object', []) :  3 | ['StateHoliday', 'StoreType', 'Assortment']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['StateHoliday', 'StoreType', 'Assortment']\n",
      "\t\t('float', [])     : 5 | ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
      "\t\t('int', [])       : 6 | ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', ...]\n",
      "\t\t('int', ['bool']) : 4 | ['Open', 'Promo', 'SchoolHoliday', 'Promo2']\n",
      "\t1.5s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 56.80 MB (3.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 398.77s of the 598.30s of remaining time.\n",
      "2025-11-23 14:24:19,244\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 27.21% memory usage per fold, 54.42%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=27.21%)\n",
      "2025-11-23 14:24:20,841\tERROR services.py:1350 -- Failed to start the dashboard , return code 0\n",
      "2025-11-23 14:24:20,843\tERROR services.py:1375 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2025-11-23 14:24:20,847\tERROR services.py:1419 -- \n",
      "The last 20 lines of /tmp/ray/session_2025-11-23_14-24-19_398426_74097/logs/dashboard.log (it contains the error message from the dashboard): \n",
      "    loop.run_until_complete(dashboard.run())\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/ray/dashboard/dashboard.py\", line 78, in run\n",
      "    await self.dashboard_head.run()\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/ray/dashboard/head.py\", line 291, in run\n",
      "    await self._configure_http_server(modules)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/ray/dashboard/head.py\", line 138, in _configure_http_server\n",
      "    self.http_server = HttpServerDashboardHead(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/ray/dashboard/http_server_head.py\", line 103, in __init__\n",
      "    raise ex\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/ray/dashboard/http_server_head.py\", line 94, in __init__\n",
      "    build_dir = setup_static_dir()\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/ray/dashboard/http_server_head.py\", line 54, in setup_static_dir\n",
      "    raise dashboard_utils.FrontendNotFoundError(\n",
      "ray.dashboard.utils.FrontendNotFoundError: [Errno 2] Dashboard build directory not found. If installing from source, please follow the additional steps required to build the dashboard(cd python/ray/dashboard/client && npm ci && npm run build): '/opt/anaconda3/envs/ag/lib/python3.11/site-packages/ray/dashboard/client/build'\n",
      "\t-668.3226\t = Validation score   (-root_mean_squared_error)\n",
      "\t379.16s\t = Training   runtime\n",
      "\t145.69s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 193.40s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t-668.3226\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 193.34s of the 193.29s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.54% memory usage per fold, 43.08%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=21.54%)\n",
      "\t-615.1488\t = Validation score   (-root_mean_squared_error)\n",
      "\t180.05s\t = Training   runtime\n",
      "\t46.72s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.80s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t-615.1488\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 595.5s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 407.3 rows/s (78368 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/sepideghorbanian/Documents/Semester_5/Research_Project/Models_group/easy\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"Models_group/hard/\"\n",
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.4.0: Fri Mar 15 00:19:22 PDT 2024; root:xnu-10063.101.17~1/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.68 GB / 8.00 GB (21.0%)\n",
      "Disk Space Avail:   53.05 GB / 228.27 GB (23.2%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"/Users/sepideghorbanian/Documents/Semester_5/Research_Project/Models_group/hard\"\n",
      "Train Data Rows:    76929\n",
      "Train Data Columns: 18\n",
      "Label Column:       Sales\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (41551, 0, 8796.03619, 5919.13579)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for group: hard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1721.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 21.57 MB (1.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  5 | ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
      "\t\t('int', [])    : 10 | ['Store', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', ...]\n",
      "\t\t('object', []) :  3 | ['StateHoliday', 'StoreType', 'Assortment']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['StateHoliday', 'StoreType', 'Assortment']\n",
      "\t\t('float', [])     : 5 | ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
      "\t\t('int', [])       : 6 | ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', ...]\n",
      "\t\t('int', ['bool']) : 4 | ['Open', 'Promo', 'SchoolHoliday', 'Promo2']\n",
      "\t0.2s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.97 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.74s of the 599.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.99%)\n",
      "\t-1258.6616\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.1s\t = Training   runtime\n",
      "\t324.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 277.35s of the 477.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.50%)\n",
      "\t-1107.5127\t = Validation score   (-root_mean_squared_error)\n",
      "\t888.66s\t = Training   runtime\n",
      "\t51.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -424.39s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.87, 'LightGBMXT_BAG_L1': 0.13}\n",
      "\t-1103.8438\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -424.56s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.87, 'LightGBMXT_BAG_L1': 0.13}\n",
      "\t-1103.8438\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1024.61s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 25.6 rows/s (9617 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/sepideghorbanian/Documents/Semester_5/Research_Project/Models_group/hard\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"Models_group/medium/\"\n",
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.4.0: Fri Mar 15 00:19:22 PDT 2024; root:xnu-10063.101.17~1/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.62 GB / 8.00 GB (32.8%)\n",
      "Disk Space Avail:   53.18 GB / 228.27 GB (23.3%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"/Users/sepideghorbanian/Documents/Semester_5/Research_Project/Models_group/medium\"\n",
      "Train Data Rows:    109894\n",
      "Train Data Columns: 18\n",
      "Label Column:       Sales\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (31311, 0, 7199.8266, 4206.003)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for group: medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2714.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 30.81 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  5 | ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
      "\t\t('int', [])    : 10 | ['Store', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', ...]\n",
      "\t\t('object', []) :  3 | ['StateHoliday', 'StoreType', 'Assortment']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['StateHoliday', 'StoreType', 'Assortment']\n",
      "\t\t('float', [])     : 5 | ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
      "\t\t('int', [])       : 6 | ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', ...]\n",
      "\t\t('int', ['bool']) : 4 | ['Open', 'Promo', 'SchoolHoliday', 'Promo2']\n",
      "\t0.3s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.96 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.69s of the 599.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.91%)\n",
      "\t-845.1061\t = Validation score   (-root_mean_squared_error)\n",
      "\t101.58s\t = Training   runtime\n",
      "\t479.65s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 232.31s of the 432.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.76%)\n",
      "\t-701.9646\t = Validation score   (-root_mean_squared_error)\n",
      "\t85.52s\t = Training   runtime\n",
      "\t432.8s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 86.19s of the 286.17s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 222 due to low memory. Expected memory usage reduced from 20.25% -> 15.0% of available memory...\n",
      "\t-945.9075\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.68s\t = Training   runtime\n",
      "\t1.91s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 62.33s of the 262.32s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 22.70% memory usage per fold, 45.39%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=22.70%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=75331, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75331, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 59.42s of the 259.40s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 156 due to low memory. Expected memory usage reduced from 28.67% -> 15.0% of available memory...\n",
      "2025-11-23 14:57:02,272\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=75332, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75332, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\t-977.2146\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.68s\t = Training   runtime\n",
      "\t1.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 51.17s of the 251.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.57%)\n",
      "\t-1118.1301\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.27s\t = Training   runtime\n",
      "\t2.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 7.04s of the 207.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.90%)\n",
      "\t-1081.3042\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.75s\t = Training   runtime\n",
      "\t2.89s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 196.73s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.96, 'RandomForestMSE_BAG_L1': 0.04}\n",
      "\t-701.8245\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 196.52s of the 196.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.65%)\n",
      "\t-708.066\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.06s\t = Training   runtime\n",
      "\t22.51s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 151.43s of the 151.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.00%)\n",
      "\t-694.8436\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.82s\t = Training   runtime\n",
      "\t2.31s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 139.53s of the 139.46s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 233 due to low memory. Expected memory usage reduced from 19.29% -> 15.0% of available memory...\n",
      "\t-705.8136\t = Validation score   (-root_mean_squared_error)\n",
      "\t91.07s\t = Training   runtime\n",
      "\t2.93s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 45.26s of the 45.19s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.74% memory usage per fold, 43.49%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=21.74%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=75409, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75409, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 42.97s of the 42.89s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 162 due to low memory. Expected memory usage reduced from 27.77% -> 15.0% of available memory...\n",
      "2025-11-23 15:00:38,078\tERROR worker.py:409 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=75408, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=75408, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 446, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/anaconda3/envs/ag/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 82, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\t-697.6501\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.15s\t = Training   runtime\n",
      "\t1.87s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 26.75s of the 26.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=6.54%)\n",
      "\t-701.2666\t = Validation score   (-root_mean_squared_error)\n",
      "\t23.35s\t = Training   runtime\n",
      "\t2.78s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 0.53s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.333, 'ExtraTreesMSE_BAG_L2': 0.286, 'LightGBM_BAG_L1': 0.143, 'NeuralNetFastAI_BAG_L2': 0.143, 'LightGBMXT_BAG_L2': 0.048, 'RandomForestMSE_BAG_L2': 0.048}\n",
      "\t-690.0474\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 599.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 14.5 rows/s (13737 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/sepideghorbanian/Documents/Semester_5/Research_Project/Models_group/medium\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a model for each group\n",
    "group_models = {}\n",
    "\n",
    "for group in meta_df[\"group\"].unique():\n",
    "    print(\"Training model for group:\", group)\n",
    "    \n",
    "    # get store names in this group\n",
    "    store_names = meta_df[meta_df[\"group\"] == group][\"label\"].tolist()\n",
    "    \n",
    "    # merge datasets from all stores in this group\n",
    "    group_df = pd.concat([stores[name] for name in store_names], ignore_index=True)\n",
    "    \n",
    "    # train model for this group\n",
    "    predictor = TabularPredictor(\n",
    "        label=\"Sales\",\n",
    "        path=f\"Models_group/{group}/\"\n",
    "    ).fit(\n",
    "        group_df,\n",
    "        presets=\"best\",\n",
    "        time_limit=600,\n",
    "        dynamic_stacking=False\n",
    "    )\n",
    "\n",
    "    group_models[group] = predictor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "95a22756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy': <autogluon.tabular.predictor.predictor.TabularPredictor at 0x17d44ba50>,\n",
       " 'hard': <autogluon.tabular.predictor.predictor.TabularPredictor at 0x17d442ad0>,\n",
       " 'medium': <autogluon.tabular.predictor.predictor.TabularPredictor at 0x152728e10>}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867bb0c3",
   "metadata": {},
   "source": [
    "## 6. Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_dataset(new_df):\n",
    "    \n",
    "    # 1. Compute metadata\n",
    "    metadata = compute_metadata(new_df)\n",
    "    meta_vec = pd.DataFrame([metadata])\n",
    "    \n",
    "    # 2. Predict group with probabilities*\n",
    "    probs = clf.predict_proba(meta_vec)[0]\n",
    "    confidence = max(probs)\n",
    "    pred_group = clf.classes_[np.argmax(probs)]\n",
    "    \n",
    "    print(\"Predicted group:\", pred_group)\n",
    "    print(\"Prediction confidence:\", confidence)\n",
    "    \n",
    "    # 3. Fallback: if confidence is too low → use global model instead\n",
    "    if confidence < 0.6:\n",
    "        print(\"Low confidence — using global model instead.\")\n",
    "        return global_predictor.predict(new_df), global_predictor.evaluate(new_df)\n",
    "    \n",
    "    # 4. Load the correct group model\n",
    "    predictor = TabularPredictor.load(f\"Models_group/{pred_group}/\")\n",
    "    \n",
    "    # 5. Predict using selected group model\n",
    "    preds = predictor.predict(new_df)\n",
    "    evals = predictor.evaluate(new_df)\n",
    "    \n",
    "    return preds, evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1bfcb",
   "metadata": {},
   "source": [
    "## 7. Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c23e6cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_rows                                743\n",
       "mean_sales                      5844.975774\n",
       "std_sales                        2904.64343\n",
       "cv_sales                           0.496947\n",
       "skew_sales                         -1.02155\n",
       "kurtosis_sales                     0.171965\n",
       "entropy_sales                      8.281397\n",
       "acf_lag1                          -0.006378\n",
       "acf_lag7                          -0.074628\n",
       "acf_lag30                           -0.0136\n",
       "weekday_seasonality_strength       0.006606\n",
       "volatility                      4123.158961\n",
       "jump_fraction                      0.052561\n",
       "promo_fraction                     0.384926\n",
       "promo_sales_corr                    0.46406\n",
       "promo2_fraction                         0.0\n",
       "mean_mutual_info                   0.130918\n",
       "max_mutual_info                    0.442137\n",
       "label                             store_632\n",
       "group                                  easy\n",
       "Name: 718, dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.iloc[718]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "42cfbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_df = stores[\"store_718\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "12c75d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted group: easy\n",
      "Prediction confidence: 0.9754722222222222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2250       7332.744629\n",
       " 2712         -4.130377\n",
       " 4306       6068.934082\n",
       " 4474       8644.786133\n",
       " 5042      12396.359375\n",
       "               ...     \n",
       " 809820     5829.947266\n",
       " 810422     6641.406738\n",
       " 810436     7836.470215\n",
       " 812348       -2.487826\n",
       " 812377     6731.804199\n",
       " Name: Sales, Length: 725, dtype: float32,\n",
       " {'root_mean_squared_error': np.float64(-536.9945376970946),\n",
       "  'mean_squared_error': -288363.125,\n",
       "  'mean_absolute_error': -372.951904296875,\n",
       "  'r2': 0.9751595854759216,\n",
       "  'pearsonr': 0.9877379406725663,\n",
       "  'median_absolute_error': -282.46875})"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict_for_dataset(incoming_df)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a4a285fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': np.float64(-483.2252021512836),\n",
       " 'mean_squared_error': -233506.609375,\n",
       " 'mean_absolute_error': -344.7164306640625,\n",
       " 'r2': 0.9798851013183594,\n",
       " 'pearsonr': 0.9898985073192784,\n",
       " 'median_absolute_error': -254.26953125}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_predictor.evaluate(incoming_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f7a5f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like the small models work better on the hard datasets but worse on the easy datasets?! And for medium is almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "37b7c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The provlem is when the decison tree predicts incorrectly and use the wrong model for it. We need to make sure that this does not happen.\n",
    "# store 264 was a good example of that. With using the simple meta data and decision tree, it was predicted an easy dataset however it was a hard one, therefore it used the easy model on it which worked awfully. (RMSE=2590)\n",
    "# But with the use of random forest and the new metadata calculation it was predicted as a hard dataset and by using the hard model the evaluation results were also much better than the global model.\n",
    "# That is why we use a threshod for the prediction score now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What meta features would you suggest to capture the actual difficulty of the dataset?\n",
    "# Randomforest or decision tree?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
